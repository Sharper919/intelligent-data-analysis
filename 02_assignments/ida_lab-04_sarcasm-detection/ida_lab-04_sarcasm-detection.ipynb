{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Лабораторна робота 4.</center></h1>\n",
    "<h2><center>Виявлення сарказму за допомогою логістичної регресії</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Виконав:** Прізвище І.П.\n",
    "\n",
    "**Варіант:** №__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В цій лабораторній роботі ми будемо подувати модель логістичної регресії для розв'язання задачі класифікації саркастичних текстів. Для цього використаємо набір даних з [наукової статі](https://arxiv.org/abs/1704.05579) «A Large Self-Annotated Corpus for Sarcasm» з понад 1 мільйоном коментарів із платформи Reddit, що позначені авторами статті як саркастичні або ні. Оброблена версія цього набору даних міститься на платформі Kaggle у формі [Набору даних Kaggle](https://www.kaggle.com/datasets/danofer/sarcasm/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зміст\n",
    "\n",
    "- [4.1. Попередній аналіз даних](#lab-4.1)\n",
    "- [4.2. Векторизація TF-IDF та логістична регресія](#lab-4.2)\n",
    "- [4.3. Інтерпретація та порівняння моделі](#lab-4.3)\n",
    "- [4.4. Розширене вдосконалення моделі](#lab-4.4)\n",
    "- [4.5. Практичне застосування результатів інтелектуального аналізу даних](#lab-4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спершу завантажте цільовий набір даних `train-balanced-sarcasm.csv` із ресурсу Kaggle за [посиланням](https://www.kaggle.com/datasets/danofer/sarcasm/data?select=train-balanced-sarcasm.csv). Збережіть файл .csv в теку з робочим файлом лабораторної роботи.\n",
    "\n",
    "Цей набір даних містить 1,3 млн. саркастичних коментарів з платформи інтернет-коментарів Reddit. Набір даних було створено шляхом вилучення коментарів з Reddit, що містять тег `\\s` (\"сарказм\"). Цей тег переважно використовується користувачами, щоб вказати на жартівливий тон їхнього коментаря, тобто такий запис не повинен сприйматися серйозно, і, як правило, є надійним показником саркастичного змісту коментаря.\n",
    "\n",
    "Дані мають збалансовану та незбалансовану (тобто справжній розподіл) версії. Реальне співвідношення несаркастичних до саркастичних коментарів становить приблизно 1:100. Оригінальний набір даних можна додатково отримати за [посиланням](https://github.com/NLPrinceton/SARC), але для лабораторної роботи він нам не потрібен.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:39:38.704867600Z",
     "start_time": "2023-11-21T14:39:38.692862900Z"
    },
    "_uuid": "ed87ab2845921166bb73ca854bfe1ef013c035e9"
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"train-balanced-sarcasm.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:39:40.010896800Z",
     "start_time": "2023-11-21T14:39:38.706865200Z"
    },
    "_uuid": "ffa03aec57ab6150f9bec0fa56cd3a5791a3e6f4"
   },
   "outputs": [],
   "source": [
    "# Виконаємо завантаження основних бібліотек\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:39:43.077555Z",
     "start_time": "2023-11-21T14:39:40.012897800Z"
    },
    "_uuid": "b23e4fc7a1973d60e0c6da8bd60f3d921542a856"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нижче переглянемо зразки цільового набору в розрізі основних ознак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:39:43.092558100Z",
     "start_time": "2023-11-21T14:39:43.078556900Z"
    },
    "_uuid": "4dc7b3787afa46c7eb0d0e33b0c41ab9821c4a27"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-18 21:03:47</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>2016-12-30 17:00:13</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  \\\n",
       "0      0                                         NC and NH.  Trumpbart   \n",
       "1      0  You do know west teams play against west teams...  Shbshb906   \n",
       "2      0  They were underdogs earlier today, but since G...   Creepeth   \n",
       "3      0  This meme isn't funny none of the \"new york ni...  icebrotha   \n",
       "4      0                    I could use one of those tools.  cush2push   \n",
       "\n",
       "            subreddit  score  ups  downs     date          created_utc  \\\n",
       "0            politics      2   -1     -1  2016-10  2016-10-16 23:55:23   \n",
       "1                 nba     -4   -1     -1  2016-11  2016-11-01 00:24:10   \n",
       "2                 nfl      3    3      0  2016-09  2016-09-22 21:45:37   \n",
       "3  BlackPeopleTwitter     -8   -1     -1  2016-10  2016-10-18 21:03:47   \n",
       "4  MaddenUltimateTeam      6   -1     -1  2016-12  2016-12-30 17:00:13   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:39:43.818068200Z",
     "start_time": "2023-11-21T14:39:43.095558600Z"
    },
    "_uuid": "0a7ed9557943806c6813ad59c3d5ebdb403ffd78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1010826 entries, 0 to 1010825\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   label           1010826 non-null  int64 \n",
      " 1   comment         1010773 non-null  object\n",
      " 2   author          1010826 non-null  object\n",
      " 3   subreddit       1010826 non-null  object\n",
      " 4   score           1010826 non-null  int64 \n",
      " 5   ups             1010826 non-null  int64 \n",
      " 6   downs           1010826 non-null  int64 \n",
      " 7   date            1010826 non-null  object\n",
      " 8   created_utc     1010826 non-null  object\n",
      " 9   parent_comment  1010826 non-null  object\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 77.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6472f52fb5ecb8bb2a6e3b292678a2042fcfe34c"
   },
   "source": [
    "Деяких коментарів бракує в наборі, тому ми видалимо відповідні рядки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:39:44.123072100Z",
     "start_time": "2023-11-21T14:39:43.777084800Z"
    },
    "_uuid": "97b2d85627fcde52a506dbdd55d4d6e4c87d3f08"
   },
   "outputs": [],
   "source": [
    "train_df.dropna(subset=[\"comment\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d51637ee70dca7693737ad0da1dbb8c6ce9230b"
   },
   "source": [
    "Переконаємось, що розглядуваний набір даних є справді збалансованим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:39:44.138071100Z",
     "start_time": "2023-11-21T14:39:44.132073900Z"
    },
    "_uuid": "addd77c640423d30fd146c8d3a012d3c14481e11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    505405\n",
       "1    505368\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b836574e5093c5eb2e9063fefe1c8d198dcba79"
   },
   "source": [
    "Розділимо дані на частини для навчання та валідації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:39:44.389073100Z",
     "start_time": "2023-11-21T14:39:44.137067500Z"
    },
    "_uuid": "c200add4e1dcbaa75164bbcc73b9c12ecb863c96"
   },
   "outputs": [],
   "source": [
    "train_texts, valid_texts, y_train, y_valid = train_test_split(\n",
    "    train_df[\"comment\"], train_df[\"label\"], random_state=17\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-4.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba1a8f65032c5954476a68e01b607655145b746d"
   },
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">4.1. Попередній аналіз даних</span>\n",
    "\n",
    "[Повернутися до змісту](#lab-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:39:44.405070600Z",
     "start_time": "2023-11-21T14:39:44.390070Z"
    },
    "_uuid": "c2c613ee2052a2c0379682adf5c23d1f751f4c3b"
   },
   "outputs": [],
   "source": [
    "# from wordcloud import STOPWORDS, WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:39:44.442068900Z",
     "start_time": "2023-11-21T14:39:44.409069Z"
    },
    "_uuid": "ae7333d67f6a17673d2aa16aed3017e2fbef9b58"
   },
   "outputs": [],
   "source": [
    "# Підготуємо об'єкт класу WordCloud для \n",
    "# можливого візуального аналізу  \n",
    "# my_wordcloud = WordCloud(\n",
    "#     background_color=\"black\",\n",
    "#     stopwords=STOPWORDS,\n",
    "#     max_words=200,\n",
    "#     max_font_size=100,\n",
    "#     random_state=17,\n",
    "#     width=800,\n",
    "#     height=400,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:2em;\">Завдання 1</span>\n",
    "\n",
    "**Для всіх варіантів:**\n",
    "\n",
    "У завданні 1 вам потрібно проаналізувати та підготувати набір даних для подальшої побудови моделей інтелектуального аналізу даних.\n",
    "\n",
    "**Для варіантів 1-2:**\n",
    "\n",
    "Проаналізуйте використання в текстах хештегів, URLs, емоджі та згадок користувачів (символ - @).\n",
    "\n",
    "**Для варіантів 3-4:**\n",
    "\n",
    "Векторизуйте текст на слова. Обрахуйте та візуалізуйте 20 найбільш вживаних слів.\n",
    "\n",
    "**Для варіантів 5-6:**\n",
    "\n",
    "Візуалізуйте розподіли саркастичних і нормальних коментарів.\n",
    "\n",
    "**Для варіантів 7-8:**\n",
    "\n",
    "Проаналізуйте, чи є деякі субредити в середньому більш «саркастичними», ніж інші.\n",
    "\n",
    "**Для варіантів 9-10:**\n",
    "\n",
    "Візуалізуйте хмарне подання слів для кожного класу.\n",
    "\n",
    "**Для варіантів 11-12:**\n",
    "\n",
    "Видаліть загальні стоп-слова з текстових даних.\n",
    "\n",
    "**Для варіантів 13-14:**\n",
    "\n",
    "Дослідіть та візуалізуйте розподіли довжини тексту для різних класів.\n",
    "\n",
    "**Для варіантів 15-16:**\n",
    "\n",
    "Напишіть функцію для очищення текстових даних (видалення спеціальних символів, нижнього регістру тощо).\n",
    "\n",
    "**Для варіантів 17-18:**\n",
    "\n",
    "Створіть хмару слів для найуживаніших слів у класі \"Саркастичний\".\n",
    "\n",
    "**Для варіантів 19-20:**\n",
    "\n",
    "Проаналізуйте, чи є деякі автори в середньому більш саркастичними, ніж інші.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-4.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "416321f19f5a27290bc5622e8b3384b7bbbd28c6"
   },
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">4.2. Векторизація TF-IDF та логістична регресія</span>\n",
    "\n",
    "[Повернутися до змісту](#lab-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:39:44.442068900Z",
     "start_time": "2023-11-21T14:39:44.424075300Z"
    },
    "_uuid": "3048a070a56b08eb4e5fe2c54b6d14905031e74a"
   },
   "outputs": [],
   "source": [
    "# Побудуємо біграми, обмежимо максимальну кількість ознак\n",
    "# і мінімальну частоту слів\n",
    "tf_idf_3 = TfidfVectorizer(ngram_range=(1, 2), max_features=5000, min_df=2)\n",
    "# Створимо об'єкт мультиноміальної логістичної регресії,\n",
    "# яка також відома як класифікатор softmax\n",
    "logit_3 = LogisticRegression(C=1, n_jobs=4, solver=\"lbfgs\", random_state=17, verbose=1)\n",
    "# Задамо sklearn's pipeline\n",
    "tfidf_logit_pipeline_3 = Pipeline([(\"tf_idf\", tf_idf), (\"logit\", logit)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:40:14.349574100Z",
     "start_time": "2023-11-21T14:39:44.500067700Z"
    },
    "_uuid": "8756bac7457218e4daf08ec276211f03971c17fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 19.9 s\n",
      "Wall time: 29.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf_idf&#x27;,\n",
       "                 TfidfVectorizer(max_features=50000, min_df=2,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                (&#x27;logit&#x27;,\n",
       "                 LogisticRegression(C=1, n_jobs=4, random_state=17,\n",
       "                                    verbose=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tf_idf&#x27;,\n",
       "                 TfidfVectorizer(max_features=50000, min_df=2,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                (&#x27;logit&#x27;,\n",
       "                 LogisticRegression(C=1, n_jobs=4, random_state=17,\n",
       "                                    verbose=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=50000, min_df=2, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, n_jobs=4, random_state=17, verbose=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tf_idf',\n",
       "                 TfidfVectorizer(max_features=50000, min_df=2,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('logit',\n",
       "                 LogisticRegression(C=1, n_jobs=4, random_state=17,\n",
       "                                    verbose=1))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_logit_pipeline.fit(train_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:40:18.961782300Z",
     "start_time": "2023-11-21T14:40:14.338567600Z"
    },
    "_uuid": "d2e47f77f999c2fb5aee9ef1de1542bc93de4c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.17 s\n",
      "Wall time: 4.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_pred = tfidf_logit_pipeline.predict(valid_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:40:19.008778Z",
     "start_time": "2023-11-21T14:40:18.963793600Z"
    },
    "_uuid": "a8f93efc3db12910eaa6d7944feebb2418714203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точність за даними валідації:  0.7210\n"
     ]
    }
   ],
   "source": [
    "print(f\"Точність за даними валідації: {accuracy_score(y_valid, valid_pred): .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:40:19.281356900Z",
     "start_time": "2023-11-21T14:40:18.997781500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Splitting the dataset\n",
    "train_texts, valid_texts, y_train, y_valid = train_test_split(\n",
    "    train_df[\"comment\"], train_df[\"label\"], random_state=17\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:40:19.296352100Z",
     "start_time": "2023-11-21T14:40:19.284354200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to encapsulate the pipeline execution\n",
    "def run_pipeline(train_texts, y_train, valid_texts):\n",
    "    # Setting up the TfidfVectorizer\n",
    "    tf_idf = TfidfVectorizer(ngram_range=(1, 2), max_features=20000, min_df=5)\n",
    "\n",
    "    # Creating a Decision Tree Classifier with limited depth\n",
    "    decision_tree = DecisionTreeClassifier(max_depth=10, random_state=17)\n",
    "\n",
    "    # Setting up the pipeline\n",
    "    tfidf_tree_pipeline = Pipeline([(\"tf_idf\", tf_idf), (\"decision_tree\", decision_tree)])\n",
    "\n",
    "    # Fitting the model\n",
    "    tfidf_tree_pipeline.fit(train_texts, y_train)\n",
    "\n",
    "    # Making predictions\n",
    "    valid_pred = tfidf_tree_pipeline.predict(valid_texts)\n",
    "    return valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:41:17.593161300Z",
     "start_time": "2023-11-21T14:40:19.311353300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         35353936 function calls (35353926 primitive calls) in 58.268 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000   58.268   29.134 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3424(run_code)\n",
      "        2    0.000    0.000   58.268   29.134 {built-in method builtins.exec}\n",
      "        1    0.146    0.146   58.268   58.268 C:\\Users\\radiu\\AppData\\Local\\Temp\\ipykernel_24332\\190850411.py:6(<module>)\n",
      "        1    0.012    0.012   58.122   58.122 C:\\Users\\radiu\\AppData\\Local\\Temp\\ipykernel_24332\\651167869.py:2(run_pipeline)\n",
      "        1    0.000    0.000   52.676   52.676 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:374(fit)\n",
      "        1    0.007    0.007   26.792   26.792 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\tree\\_classes.py:859(fit)\n",
      "        1    0.002    0.002   26.785   26.785 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\tree\\_classes.py:176(fit)\n",
      "        1   26.543   26.543   26.544   26.544 {method 'build' of 'sklearn.tree._tree.DepthFirstTreeBuilder' objects}\n",
      "        1    0.000    0.000   25.883   25.883 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:336(_fit)\n",
      "        1    0.000    0.000   25.883   25.883 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\joblib\\memory.py:352(__call__)\n",
      "        1    0.004    0.004   25.883   25.883 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:883(_fit_transform_one)\n",
      "        1    0.000    0.000   25.879   25.879 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2107(fit_transform)\n",
      "        1    0.350    0.350   25.651   25.651 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1342(fit_transform)\n",
      "        2   10.068    5.034   24.030   12.015 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1258(_count_vocab)\n",
      "  1010773    1.195    0.000   10.551    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:75(_analyze)\n",
      "  1010773    3.707    0.000    5.741    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:245(_word_ngrams)\n",
      "        1    0.005    0.005    5.435    5.435 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:449(predict)\n",
      "        1    0.000    0.000    5.373    5.373 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2139(transform)\n",
      "        1    0.001    0.001    5.317    5.317 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1410(transform)\n",
      "        1    1.256    1.256    3.898    3.898 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1203(_sort_features)\n",
      "        1    1.791    1.791    2.689    2.689 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1217(_limit_features)\n",
      "  1010773    2.600    0.000    2.600    0.000 {method 'findall' of 're.Pattern' objects}\n",
      "        5    2.531    0.506    2.531    0.506 {built-in method builtins.sorted}\n",
      "  1010773    1.173    0.000    1.173    0.000 {method 'extend' of 'array.array' objects}\n",
      "  9110097    1.043    0.000    1.043    0.000 {method 'join' of 'str' objects}\n",
      "  152/151    0.982    0.006    0.982    0.007 {built-in method numpy.asarray}\n",
      " 10120923    0.791    0.000    0.791    0.000 {method 'append' of 'list' objects}\n",
      "  1010773    0.587    0.000    0.587    0.000 {method 'extend' of 'list' objects}\n",
      "  1010773    0.408    0.000    0.532    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:213(decode)\n",
      "  1010773    0.278    0.000    0.482    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:49(_preprocess)\n",
      "        5    0.000    0.000    0.375    0.075 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:510(_mul_dispatch)\n",
      "  1966880    0.367    0.000    0.367    0.000 {method 'add' of 'set' objects}\n",
      "  120/119    0.215    0.002    0.317    0.003 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "       10    0.000    0.000    0.282    0.028 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:629(check_array)\n",
      "        7    0.008    0.001    0.282    0.040 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:447(_ensure_sparse_format)\n",
      "        5    0.000    0.000    0.274    0.055 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1159(sort_indices)\n",
      "        3    0.269    0.090    0.269    0.090 {built-in method scipy.sparse._sparsetools.csr_sort_indices}\n",
      "        5    0.000    0.000    0.267    0.053 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\base.py:483(_validate_data)\n",
      "        2    0.000    0.000    0.227    0.113 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1693(transform)\n",
      "        3    0.001    0.000    0.222    0.074 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:599(sum)\n",
      "        3    0.001    0.000    0.221    0.074 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:1050(sum)\n",
      "        2    0.000    0.000    0.209    0.105 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:923(_document_frequency)\n",
      "        2    0.000    0.000    0.209    0.105 <__array_function__ internals>:177(bincount)\n",
      "        3    0.000    0.000    0.207    0.069 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:632(__rmatmul__)\n",
      "        3    0.000    0.000    0.207    0.069 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:605(_rmul_dispatch)\n",
      "        3    0.000    0.000    0.206    0.069 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:480(_mul_vector)\n",
      "        3    0.206    0.069    0.206    0.069 {built-in method scipy.sparse._sparsetools.csc_matvec}\n",
      "  1010773    0.204    0.000    0.204    0.000 {method 'lower' of 'str' objects}\n",
      "  1010777    0.200    0.000    0.200    0.000 {built-in method builtins.min}\n",
      "  2021811    0.189    0.000    0.189    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.168    0.084 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:589(__mul__)\n",
      "        2    0.000    0.000    0.168    0.084 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:507(_mul_sparse_matrix)\n",
      "        4    0.000    0.000    0.156    0.039 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:348(asformat)\n",
      "        1    0.003    0.003    0.155    0.155 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_csr.py:172(tocsc)\n",
      "        1    0.135    0.135    0.135    0.135 {built-in method scipy.sparse._sparsetools.csr_tocsc}\n",
      "        2    0.132    0.066    0.132    0.066 {built-in method scipy.sparse._sparsetools.csr_matmat}\n",
      "  1011483    0.124    0.000    0.124    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.117    0.117 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_index.py:46(__getitem__)\n",
      "        1    0.000    0.000    0.117    0.117 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_csr.py:320(_get_sliceXarray)\n",
      "        1    0.000    0.000    0.117    0.117 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:754(_minor_index_fancy)\n",
      "  1010773    0.112    0.000    0.112    0.000 {method 'keys' of 'dict' objects}\n",
      "        2    0.110    0.055    0.110    0.055 {method 'take' of 'numpy.ndarray' objects}\n",
      "  1010773    0.089    0.000    0.089    0.000 {method 'values' of 'dict' objects}\n",
      "        1    0.084    0.084    0.084    0.084 {built-in method scipy.sparse._sparsetools.csr_column_index2}\n",
      "       18    0.067    0.004    0.067    0.004 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        2    0.000    0.000    0.064    0.032 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_data.py:68(astype)\n",
      "        1    0.000    0.000    0.057    0.057 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\tree\\_classes.py:402(predict)\n",
      "        1    0.001    0.001    0.057    0.057 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1643(fit)\n",
      "        8    0.000    0.000    0.054    0.007 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:96(_assert_all_finite)\n",
      "        7    0.000    0.000    0.054    0.008 <__array_function__ internals>:177(sum)\n",
      "        7    0.000    0.000    0.054    0.008 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2162(sum)\n",
      "        8    0.000    0.000    0.054    0.007 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:69(_wrapreduction)\n",
      "        2    0.000    0.000    0.042    0.021 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1758(normalize)\n",
      "        1    0.000    0.000    0.040    0.040 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\tree\\_classes.py:389(_validate_X_predict)\n",
      "       13    0.036    0.003    0.036    0.003 {method 'astype' of 'numpy.ndarray' objects}\n",
      "        2    0.036    0.018    0.036    0.018 {built-in method scipy.sparse._sparsetools.csr_matmat_maxnnz}\n",
      "        2    0.000    0.000    0.034    0.017 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_data.py:30(_deduped_data)\n",
      "        2    0.000    0.000    0.034    0.017 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1111(sum_duplicates)\n",
      "       44    0.034    0.001    0.034    0.001 {built-in method numpy.array}\n",
      "        3    0.000    0.000    0.034    0.011 <__array_function__ internals>:177(unique)\n",
      "        3    0.002    0.001    0.034    0.011 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\lib\\arraysetops.py:138(unique)\n",
      "       14    0.000    0.000    0.034    0.002 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:26(__init__)\n",
      "        1    0.033    0.033    0.033    0.033 {built-in method scipy.sparse._sparsetools.csr_column_index1}\n",
      "        3    0.009    0.003    0.032    0.011 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\lib\\arraysetops.py:323(_unique1d)\n",
      "        2    0.026    0.013    0.026    0.013 {sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l2}\n",
      "        3    0.019    0.006    0.019    0.006 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "        5    0.000    0.000    0.014    0.003 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:51(_wrapfunc)\n",
      "        4    0.000    0.000    0.014    0.003 {method 'sum' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.014    0.003 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\_methods.py:46(_sum)\n",
      "        1    0.013    0.013    0.013    0.013 {method 'predict' of 'sklearn.tree._tree.Tree' objects}\n",
      "        3    0.000    0.000    0.012    0.004 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:287(sum)\n",
      "        2    0.000    0.000    0.011    0.005 <__array_function__ internals>:177(cumsum)\n",
      "        2    0.000    0.000    0.011    0.005 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2497(cumsum)\n",
      "        2    0.011    0.005    0.011    0.005 {method 'cumsum' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.011    0.005 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1224(_with_data)\n",
      "        4    0.010    0.003    0.010    0.003 {method 'copy' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.010    0.010 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\multiclass.py:198(check_classification_targets)\n",
      "        1    0.000    0.000    0.010    0.010 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\multiclass.py:221(type_of_target)\n",
      "        1    0.000    0.000    0.010    0.010 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_array_api.py:83(unique_values)\n",
      "        1    0.007    0.007    0.007    0.007 {built-in method scipy.sparse._sparsetools.csr_sum_duplicates}\n",
      "        2    0.007    0.004    0.007    0.004 {method 'sort' of 'numpy.ndarray' objects}\n",
      "        5    0.000    0.000    0.005    0.001 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1127(__get_sorted)\n",
      "        4    0.005    0.001    0.005    0.001 {built-in method scipy.sparse._sparsetools.csr_has_sorted_indices}\n",
      "        2    0.000    0.000    0.004    0.002 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1081(__get_has_canonical_format)\n",
      "        2    0.004    0.002    0.004    0.002 {built-in method scipy.sparse._sparsetools.csr_has_canonical_format}\n",
      "        2    0.000    0.000    0.004    0.002 <__array_function__ internals>:177(where)\n",
      "        1    0.000    0.000    0.004    0.004 <__array_function__ internals>:177(argmax)\n",
      "        1    0.000    0.000    0.004    0.004 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1127(argmax)\n",
      "        1    0.004    0.004    0.004    0.004 {method 'argmax' of 'numpy.ndarray' objects}\n",
      "        3    0.002    0.001    0.002    0.001 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.002    0.002 <__array_function__ internals>:177(copy)\n",
      "        1    0.000    0.000    0.002    0.002 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\lib\\function_base.py:870(copy)\n",
      "        5    0.000    0.000    0.002    0.000 <__array_function__ internals>:177(copyto)\n",
      "        1    0.002    0.002    0.002    0.002 {built-in method numpy.ascontiguousarray}\n",
      "        4    0.000    0.000    0.001    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\numeric.py:149(ones)\n",
      "        1    0.000    0.000    0.001    0.001 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_construct.py:73(diags)\n",
      "        3    0.000    0.000    0.001    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\base.py:592(_validate_params)\n",
      "       35    0.000    0.000    0.001    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:147(get_index_dtype)\n",
      "  191/189    0.000    0.000    0.001    0.000 {built-in method builtins.hasattr}\n",
      "        1    0.000    0.000    0.001    0.001 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\numeric.py:289(full)\n",
      "        5    0.000    0.000    0.001    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:1322(check_is_fitted)\n",
      "        2    0.000    0.000    0.001    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:1381(<listcomp>)\n",
      "        2    0.000    0.000    0.001    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1734(idf_)\n",
      "       14    0.000    0.000    0.001    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:136(check_format)\n",
      "        4    0.000    0.000    0.001    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\base.py:153(get_params)\n",
      "        3    0.000    0.000    0.001    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:28(validate_parameter_constraints)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\base.py:122(_get_param_names)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:983(tocsr)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_csr.py:135(transpose)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:3111(signature)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:2859(from_callable)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:2246(_signature_from_callable)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:2152(_signature_from_function)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_dia.py:392(tocoo)\n",
      "       36    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:74(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:78(_csc_container)\n",
      "       22    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "       72    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\getlimits.py:648(__init__)\n",
      "    63/62    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:103(make_constraint)\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
      "       15    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1168(prune)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:1207(check_random_state)\n",
      "      102    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\abc.py:117(__instancecheck__)\n",
      "        8    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:320(_num_samples)\n",
      "       75    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(can_cast)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_coo.py:372(tocsr)\n",
      "       16    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:295(check_shape)\n",
      "       16    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\_ufunc_config.py:32(seterr)\n",
      "      102    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(argsort)\n",
      "       13    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:211(isscalarlike)\n",
      "       14    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:467(is_satisfied_by)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1012(argsort)\n",
      "        6    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:226(_ascontainer)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_dia.py:89(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_index.py:148(_validate_indices)\n",
      "        4    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(atleast_1d)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:214(_validate_steps)\n",
      "       16    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_data.py:20(__init__)\n",
      "       20    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_array_api.py:90(get_namespace)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:82(_validate_names)\n",
      "        8    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\_ufunc_config.py:434(__exit__)\n",
      "        8    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\_ufunc_config.py:429(__enter__)\n",
      "       44    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:2498(__init__)\n",
      "      113    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "       13    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\numeric.py:1873(isscalar)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:398(parent)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\contextlib.py:76(inner)\n",
      "        6    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:380(asmatrix)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method numpy.frombuffer}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:173(get_params)\n",
      "       14    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:238(isshape)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:30(_get_params)\n",
      "       11    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:446(__contains__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_coo.py:127(__init__)\n",
      "       28    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\_config.py:30(get_config)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_construct.py:173(<listcomp>)\n",
      "       67    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:291(nnz)\n",
      "        1    0.000    0.000    0.000    0.000 {function SeedSequence.generate_state at 0x0000016E041ED940}\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\shape_base.py:23(atleast_1d)\n",
      "       16    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:105(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\codeop.py:142(__call__)\n",
      "       43    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:749(__getattr__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\multiclass.py:126(is_multilabel)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "    21/18    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:167(__array_finalize__)\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\base.py:394(_check_feature_names)\n",
      "       16    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\_ufunc_config.py:131(geterr)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_index.py:172(_asindices)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:2781(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method scipy.sparse._sparsetools.coo_tocsr}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "    29/28    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\abc.py:121(__subclasscheck__)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:272(validateaxis)\n",
      "       48    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:308(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\_methods.py:38(_amax)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_coo.py:266(_check)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:423(build_analyzer)\n",
      "       35    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\getlimits.py:659(min)\n",
      "       46    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:1301(isspmatrix)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\base.py:136(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_available_if.py:25(__get__)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_csr.py:333(isspmatrix_csr)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_array_api.py:168(_asarray_with_order)\n",
      "        8    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:547(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(ravel)\n",
      "       63    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:108(getnnz)\n",
      "       14    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:462(_has_valid_type)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:1385(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_index.py:267(_unpack_index)\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\base.py:348(_check_n_features)\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:1870(_get_feature_names)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\base.py:742(__iter__)\n",
      "    29/28    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "      149    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:119(get_shape)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:202(get_sum_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:590(_pandas_dtype_needs_early_conversion)\n",
      "        8    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:555(is_satisfied_by)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\numerictypes.py:356(issubdtype)\n",
      "       25    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "       44    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\enum.py:358(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\tree\\_classes.py:506(_prune_tree)\n",
      "       28    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\_config.py:22(_get_threadlocal_config)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(amax)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "       30    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\_lib\\_util.py:143(_prune_array)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:267(_num_features)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:216(isintlike)\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1755(ravel)\n",
      "        7    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\series.py:708(_values)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method numpy.seterrobj}\n",
      "        6    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1143(__set_sorted)\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\warnings.py:165(simplefilter)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:349(check_memory)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\contextlib.py:123(__exit__)\n",
      "       22    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "       33    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:258(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\contextlib.py:261(helper)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2677(amax)\n",
      "       61    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:226(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:494(unwrap)\n",
      "       37    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\getlimits.py:672(max)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\lib\\arraysetops.py:125(_unpack_tuple)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\joblib\\memory.py:991(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\numerictypes.py:282(issubclass_)\n",
      "        9    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\series.py:596(dtype)\n",
      "       66    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_data.py:23(_get_dtype)\n",
      "       10    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:571(_ensure_no_complex_data)\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\warnings.py:181(_add_filter)\n",
      "       99    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\contextlib.py:86(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2066(internal_values)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
      "       48    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:2830(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_dia.py:446(isspmatrix_dia)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:249(_iter)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        4    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(ndim)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:353(build_tokenizer)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\random.py:791(getrandbits)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(tile)\n",
      "        3    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(empty_like)\n",
      "       17    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_array_api.py:63(__getattr__)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\_methods.py:42(_amin)\n",
      "       32    0.000    0.000    0.000    0.000 {built-in method numpy.geterrobj}\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:125(_set_self)\n",
      "       11    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_array_api.py:70(asarray)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\dtypes\\common.py:1278(is_bool_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:522(__init__)\n",
      "       15    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:93(to_native)\n",
      "       28    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(concatenate)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_index.py:376(_compatible_boolean_index)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:22(upcast)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "        9    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2055(dtype)\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\warnings.py:458(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\lib\\shape_base.py:1191(tile)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(reshape)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:44(check)\n",
      "      128    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:2548(name)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\base.py:151(<listcomp>)\n",
      "       62    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "       75    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\multiarray.py:498(can_cast)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\base.py:1023(is_classifier)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\contextlib.py:114(__enter__)\n",
      "       10    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:581(_check_estimator_name)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\joblib\\memory.py:104(_store_backend_factory)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\accessor.py:178(__get__)\n",
      "       14    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\re.py:250(compile)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\generic.py:5888(__getattr__)\n",
      "       33    0.000    0.000    0.000    0.000 {built-in method _operator.index}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:198(reshape)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:530(is_satisfied_by)\n",
      "       44    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\enum.py:670(__new__)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\traitlets\\traitlets.py:692(__get__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method nt.urandom}\n",
      "       16    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:564(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\AppData\\Local\\Temp\\ipykernel_24332\\190850411.py:8(<module>)\n",
      "        7    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\_ufunc_config.py:425(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:268(isdense)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\tree\\_classes.py:828(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1033(_handle_fromlist)\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3121(ndim)\n",
      "       11    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:328(is_satisfied_by)\n",
      "        8    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:70(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1979(__init__)\n",
      "       44    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\joblib\\memory.py:1025(cache)\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:73(isclass)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:56(upcast_char)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:398(__init__)\n",
      "       80    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:2560(kind)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\re.py:289(_compile)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:326(build_preprocessor)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\dtypes\\common.py:192(is_sparse)\n",
      "       48    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:313(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1494(_make_int_array)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:73(_coo_container)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_coo.py:240(getnnz)\n",
      "       15    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:262(is_satisfied_by)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:531(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\arrays\\sparse\\accessor.py:29(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\tree\\_classes.py:121(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:307(_final_estimator)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_index.py:361(_first_element_bool)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_base.py:83(_csr_container)\n",
      "        8    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:159(isfunction)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\IPython\\core\\compilerop.py:180(extra_flags)\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\warnings.py:437(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.vars}\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383(_check_stop_words_consistency)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\multiarray.py:341(where)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1103(__set_has_canonical_format)\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\warnings.py:477(__exit__)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:319(_check_fit_params)\n",
      "       36    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_csr.py:231(_swap)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:514(_is_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:407(_check_params)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\traitlets\\traitlets.py:654(get)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\series.py:846(__array__)\n",
      "       15    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_csc.py:230(_swap)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:373(get_stop_words)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1164(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(atleast_2d)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_index.py:352(_maybe_bool_ndarray)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\arrays\\sparse\\accessor.py:45(_validate)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2006(_block)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:653(is_satisfied_by)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\dtypes\\generic.py:45(_instancecheck)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1637(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_index.py:313(_check_ellipsis)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method _operator.lt}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:135(getdata)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\series.py:603(dtypes)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "        7    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\validation.py:962(_check_large_sparse)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3376(compare)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\dtypes\\common.py:1556(get_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\dtypes\\generic.py:40(_check)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\shape_base.py:81(atleast_2d)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:505(_check_vocabulary)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2070(_check_params)\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method _operator.ge}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:197(_check_stop_list)\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
      "        7    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2157(_sum_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525(_warn_for_unused_params)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_sputils.py:109(getdtype)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.repr}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\indexing.py:139(iloc)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_compressed.py:714(_major_slice)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\inspect.py:2865(parameters)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:500(dtype)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\__init__.py:953(_print_elapsed_time)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\joblib\\logger.py:67(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:312(_log_message)\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\multiarray.py:1071(copyto)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\joblib\\memory.py:349(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:508(is_satisfied_by)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:654(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:145(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\pandas\\core\\dtypes\\common.py:1433(is_extension_array_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\shape_base.py:19(_atleast_1d_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\IPython\\core\\interactiveshell.py:1227(user_global_ns)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'intersection' of 'set' objects}\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2493(_cumsum_dispatcher)\n",
      "        8    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:272(is_satisfied_by)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\lib\\function_base.py:866(_copy_dispatcher)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\lib\\arraysetops.py:133(_unique_dispatcher)\n",
      "        5    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1751(_ravel_dispatcher)\n",
      "        4    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3117(_ndim_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\lib\\shape_base.py:1187(_tile_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:475(_validate_vocabulary)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _operator.gt}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\pipeline.py:320(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1008(_argsort_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\multiarray.py:80(empty_like)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\multiarray.py:883(bincount)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:515(_validate_ngram_range)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:92(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1123(_argmax_dispatcher)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:253(_collapse)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2672(_amax_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\lib\\shape_base.py:1263(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\scipy\\sparse\\_csc.py:124(tocsc)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\multiarray.py:148(concatenate)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\shape_base.py:77(_atleast_2d_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\site-packages\\numpy\\core\\fromnumeric.py:193(_reshape_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\radiu\\anaconda3\\envs\\courses\\lib\\contextlib.py:63(_recreate_cm)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x16e091c1a00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Profiling the pipeline execution\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# Run the pipeline\n",
    "valid_pred = run_pipeline(train_texts, y_train, valid_texts)\n",
    "\n",
    "profiler.disable()\n",
    "\n",
    "# Print the profiling results\n",
    "stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "stats.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:42:13.060465400Z",
     "start_time": "2023-11-21T14:42:13.003466500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5903662136813695"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_result = accuracy_score(y_valid, valid_pred)\n",
    "\n",
    "my_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:2em;\">Завдання 2</span>\n",
    "\n",
    "**Для всіх варіантів:**\n",
    "\n",
    "У завданні 2 вам потрібно доповнити побудовані на попередньому кроці векторизатор та модель логістичної регресії.\n",
    "\n",
    "**Для варіантів 1-2:**\n",
    "\n",
    "Використайте N-грами у векторизаторі TF-IDF та поясніть, як вони працюють.\n",
    "\n",
    "**Для варіантів 3-4:**\n",
    "\n",
    "Дослідіть вплив регулярізації L1 (Lasso) і L2 (Ridge) на побудовану модель логістичної регресії. Зробіть висновок щодо впливу певного типу регулярізації (Lasso та Ridge) на результат моделювання.\n",
    "\n",
    "**Для варіантів 5-6:**\n",
    "\n",
    "Проведіть експерименти з параметром `max_features` у векторизаторі TF-IDF і зробіть висновок щодо його впливу на якість створених ознак та точність класифікації.\n",
    "\n",
    "**Для варіантів 7-8:**\n",
    "\n",
    "Проведіть експерименти з різними пороговими значеннями для моделі логістичної регресії. Дослідіть, як зміна порогу впливає на частку правильних відповідей, яку генерує побудована модель.\n",
    "\n",
    "**Для варіантів 9-10:**\n",
    "\n",
    "Застосуйте k-кратну перехресну перевірку (k-fold cross-validation) до побудованої моделі логістичної регресії та порівняйте результати за валідаційним набором. Якими є переваги та недоліки перехресної перевірки?\n",
    "\n",
    "**Для варіантів 11-12:**\n",
    "\n",
    "Інтерпретуйте результати моделі логістичної регресії, з огляду на значення коефіцієнтів цієї моделі. Як отримані значення вплинули на результат задачі класифікації?\n",
    "\n",
    "**Для варіантів 13-14:**\n",
    "\n",
    "Візуалізуйте та інтерпретуйте криві навчання та валідації побудованої логістичної регресії.\n",
    "\n",
    "**Для варіантів 15-16:**\n",
    "\n",
    "Налаштуйте наявні гіперпараметри моделі логістичної регресії за механізмом `GridSearchCV`.\n",
    "\n",
    "**Для варіантів 17-18:**\n",
    "\n",
    "Вилучіть та візуалізуйте назви ознак із векторизатора TF-IDF.\n",
    "\n",
    "**Для варіантів 19-20:**\n",
    "\n",
    "Проаналізуйте ознаки, які були створені векторизатором TF-IDF. Дослідіть вплив різних слів та їхні відповідні TF-IDF-оцінки.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-4.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fefd0178f43ce832031653be70f0a0e47f62cf4c"
   },
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">4.3. Інтерпретація та порівняння моделі</span>\n",
    "\n",
    "[Повернутися до змісту](#lab-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:41:17.605160200Z",
     "start_time": "2023-11-21T14:41:17.590161300Z"
    },
    "_uuid": "247a13fd3ae4d5c015c0ca0489a9a95d72ad7e9f"
   },
   "outputs": [],
   "source": [
    "# Довідково: Нижче подамо матрицю невідповідностей\n",
    "def plot_confusion_matrix(\n",
    "    actual,\n",
    "    predicted,\n",
    "    classes,\n",
    "    normalize=False,\n",
    "    title=\"Confusion matrix\",\n",
    "    figsize=(7, 7),\n",
    "    cmap=plt.cm.Blues,\n",
    "    path_to_save_fig=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    cm = confusion_matrix(actual, predicted).T\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"Predicted label\")\n",
    "    plt.xlabel(\"True label\")\n",
    "\n",
    "    if path_to_save_fig:\n",
    "        plt.savefig(path_to_save_fig, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:2em;\">Завдання 3</span>\n",
    "\n",
    "**Для всіх варіантів:**\n",
    "\n",
    "У завданні 3 вам потрібно інтерпретувати отримані результати щодо передбачення саркастичного тексту.\n",
    "\n",
    "**Для варіантів 1-2:**\n",
    "\n",
    "Візуалізуйте на одному графіку криві навчання та валідації побудованої регресійної моделі. Порівняйте обидві криві, зробіть висновок щодо якості навченої моделі.\n",
    "\n",
    "**Для варіантів 3-4:**\n",
    "\n",
    "Обрахуйте та інтерпретуйте співвідношення шансів для конкретних ознак, з огляду на те як вони пов’язані з можливістю зустріти саркастичний текст.\n",
    "\n",
    "**Для варіантів 5-6:**\n",
    "\n",
    "Виконайте візуальний аналіз тих випадків, за яких модель логістичної регресії дала неправильні прогнози, і запропонуйте стратегії для покращення ефективності моделі на основі цього аналізу.\n",
    "\n",
    "**Для варіантів 7-8:**\n",
    "\n",
    "Побудуйте модель дерева рішень на тих самих даних. Порівняйте її ефективність із моделлю логістичної регресії та обговоріть плюси та мінуси кожної моделі.\n",
    "\n",
    "**Для варіантів 9-10:**\n",
    "\n",
    "Побудуйте графіки часткової залежності ([partial dependence plots (PDP)](https://scikit-learn.org/stable/modules/partial_dependence.html#:~:text=Partial%20dependence%20plots%20(PDP)%20show,the%20'complement'%20features).)) для 5 найбільш значущих ознак у побудованій моделі логістичної регресії. Поясніть, як PDP відображають зв’язок між ознакою та прогнозованим результатом, зберігаючи інші ознаки незмінними. Інтерпретуйте ці графіки для розглядуваної задачі виявлення сарказму.\n",
    "\n",
    "**Для варіантів 11-12:**\n",
    "\n",
    "Оцініть побудовану модель логістичної регресії за допомогою кількох статистичних метрик (accuracy, precision, recall, F1-score) та зробіть висновок щодо якості моделі з огляду на значення цих метрик. Для виконання завдання використайте клас [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) бібліотеки scikit-learn.\n",
    "\n",
    "**Для варіантів 13-14:**\n",
    "\n",
    "Проаналізуйте та інтерпретуйте ті випадки, які побудована модель логістичної регресії класифікувала неправильно.\n",
    "\n",
    "**Для варіантів 15-16:**\n",
    "\n",
    "Побудуйте та інтерпретуйте криві навчання та валідації для побудованої моделі логістичної регресії. Проаналізуйте, що ці криві відображають з огляду на ефективність моделі та її можливе недонавчання або перенавчання.\n",
    "\n",
    "**Для варіантів 17-18:**\n",
    "\n",
    "Виконайте візуальний аналіз помилок побудованої моделі. Запропонуйте та реалізуйте стратегії для покращення моделі та переобрахуйте її для розв'язання задачі виявлення саркастичних текстів.\n",
    "\n",
    "**Для варіантів 19-20:**\n",
    "\n",
    "Побудуйте модель лінійної регресії на тих самих даних, перетворивши цільову змінну за необхідності. Порівняйте ефективність моделі лінійної регресії із моделлю логістичної регресії та обговоріть, чому лінійна регресія може бути непридатною для цього завдання.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-4.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5648f6ad7a14ef3a582909f7c0c72c4fc80204aa"
   },
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">4.4. Розширене вдосконалення моделі</span>\n",
    "\n",
    "[Повернутися до змісту](#lab-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:2em;\">Завдання 4</span>\n",
    "\n",
    "**Для всіх варіантів:**\n",
    "\n",
    "У завданні 4 вам потрібно використати різноманітні програмні механізми для покращення роботи моделі.\n",
    "\n",
    "**Для варіантів 1-2:**\n",
    "\n",
    "Побудуйте векторизатори TF-IDF окремо для коментарів і субредітів. Далі об’єднайте ці новостворені ознаки разом та побудуйте нову модель логістичної регресії з використанням [sklearn.pipeline.Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). Порівняйте результати роботи нової моделі із початковою за показником частки правильних відповідей.\n",
    "\n",
    "**Для варіантів 3-4:**\n",
    "\n",
    "Проаналізуйте вплив ознак рівня символів, таких як n-грами символів, на ефективність класифікації за моделлю логістичної регресії. Перевірте гіпотезу про те, що певні шаблони символів вказують на сарказм у тексті.\n",
    "\n",
    "**Для варіантів 5-6:**\n",
    "\n",
    "Використайте альтернативний векторизатор зі списку [sklearn.feature_extraction.text](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text) для подання тексту в числовий формат. Побудуйте нову модель логістичної регресії та проведіть за нею класифікацію текстів на предмет наявності сарказму. Порівняйте результати класифікації за новою моделлю (з новим векторизатором) з результатами класифікації початкової моделі.\n",
    "\n",
    "**Для варіантів 7-8:**\n",
    "\n",
    "Побудуйте та інтерпретуйте шлях регуляризації для моделі логістичної регресії. Використайте цей аналіз, щоб вибрати відповідний рівень регуляризації.\n",
    "\n",
    "**Для варіантів 9-10:**\n",
    "\n",
    "Порівняйте побудовану модель логістичної регресії з іншою моделлю (дерево рішень, лінійна регресія, k-найближчих сусідів тощо) за показником частки правильних відповідей. Зробіть висновок щодо ефективності роботи моделей.\n",
    "\n",
    "**Для варіантів 11-12:**\n",
    "\n",
    "Використайте техніки урізноманітнення текстових даних ([data augmentation](https://neptune.ai/blog/data-augmentation-in-python)), щоб збільшити розмір і різноманітність навчальних даних. Обговоріть обрані методи та їхній вплив на роботу моделі.\n",
    "\n",
    "**Для варіантів 13-14:**\n",
    "\n",
    "Застосуйте такі механізми обробки текстової інформації, як виправлення орфографії чи нормалізація сленгу. Проаналізуйте їх вплив на ефективність моделі логістичної регресії.\n",
    "\n",
    "**Для варіантів 15-16:**\n",
    "\n",
    "Визначте та відфільтруйте викиди в наборі даних. Обґрунтуйте обрання методу виявлення викидів та проаналізуйте його вплив на ефективність моделі.\n",
    "\n",
    "**Для варіантів 17-18:**\n",
    "\n",
    "Виконайте стратифіковану k-кратну перехресну перевірку (stratified k-fold cross-validation), щоб забезпечити збереження розподілу класів у кожній складці. Проаналізуйте вплив стратифікації на результат моделі.\n",
    "\n",
    "**Для варіантів 19-20:**\n",
    "\n",
    "Відкалібруйте результати ймовірностей за допомогою моделі логістичної регресії, використовуючи такі методи, як ізотонічна регресія ([Isotonic regression](https://scikit-learn.org/stable/modules/isotonic.html)) або масштабування Платта ([Platt scaling](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html)). Проаналізуйте важливість добре відкаліброваних ймовірностей та їх вплив на ефективність моделі.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-4.5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">4.5. Практичне застосування результатів інтелектуального аналізу даних</span>\n",
    "\n",
    "[Повернутися до змісту](#lab-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:2em;\">Завдання 5</span>\n",
    "\n",
    "У завданні 5 поміркуйте над застосуванням моделі логістичної регресії (і не тільки) для розв'язання практичних завдань. Проаналізуйте складнощі, що пов’язані з цією проблемою.\n",
    "\n",
    "**Для варіанту 1:**\n",
    "\n",
    "Запропонуйте технічні кроки для розгортання побудованої моделі у виробничому середовищі.\n",
    "\n",
    "**Для варіанту 2:**\n",
    "\n",
    "Обговоріть стратегії адаптації моделі до роботи з текстом на різних мовах, з огляду на додаткові виклики та складнощі, що із цим пов’язані.\n",
    "\n",
    "**Для варіанту 3:**\n",
    "\n",
    "Запропонуйте стратегії налаштування моделі для постійного навчання та вдосконалення на основі відгуків користувачів або нових даних.\n",
    "\n",
    "**Для варіанту 4:**\n",
    "\n",
    "Запропонуйте як налаштувати моніторинг розгорнутої моделі та стратегії постійної підтримки моделі.\n",
    "\n",
    "**Для варіанту 5:**\n",
    "\n",
    "Оцініть модель логістичної регресії, з огляду на її ефективність, користувацький досвід та етичні міркування, щоб отримати цілісне уявлення про її застосовність і можливість для вдосконалення.\n",
    "\n",
    "**Для варіанту 6:**\n",
    "\n",
    "Запропонуйте стратегії, які могли б забезпечити високу постійну точність моделі, з огляду на те, що основні дані змінюються із часом.\n",
    "\n",
    "**Для варіанту 7:**\n",
    "\n",
    "Оцініть стійкість моделі до атак зловмисників, коли вхідним текстом навмисно маніпулюють, щоб ввести модель в оману. Проаналізуйте стратегії, щоб зробити модель більш стійкою до таких атак.\n",
    "\n",
    "**Для варіанту 8:**\n",
    "\n",
    "Запропонуйте, як можна використати відгуки користувачів для покращення моделі та підвищення її ефективності.\n",
    "\n",
    "**Для варіанту 9:**\n",
    "\n",
    "Переконайтеся, що модель і її розгортання відповідають відповідним правовим і регуляторним стандартам, особливо щодо конфіденційності та безпеки даних користувачів.\n",
    "\n",
    "**Для варіанту 10:**\n",
    "\n",
    "Запропонуйте нові шляхи для виявлення сарказму в тексті.\n",
    "\n",
    "**Для варіанту 11:**\n",
    "\n",
    "Оцініть потенційні упередження в моделі в разі застосування в реальних сценаріях виявлення сарказму та обговоріть стратегії для забезпечення справедливості прийняття рішень.\n",
    "\n",
    "**Для варіанту 12:**\n",
    "\n",
    "Обговоріть майбутні тенденції та нові технології, які можуть вплинути на сферу класифікації текстів і виявлення сарказму. Запропонуйте шляхи інтеграції цих досягнень у поточний робочий процес.\n",
    "\n",
    "**Для варіанту 13:**\n",
    "\n",
    "Оцініть стійкість моделі до можливих негативних зовнішніх впливів.\n",
    "\n",
    "**Для варіанту 14:**\n",
    "\n",
    "Виділіть як мінімум 5 етичних проблем, що пов’язані із застосуванням моделі в реальних сценаріях.\n",
    "\n",
    "**Для варіанту 15:**\n",
    "\n",
    "Обговоріть важливість пояснюваності та прозорості моделі, особливо в тих програмних застосунках, де користувачі взаємодіють із моделлю. Запропонуйте шляхи покращення цих аспектів.\n",
    "\n",
    "**Для варіанту 16:**\n",
    "\n",
    "Обговоріть, які показники ефективності є найбільш важливими під час практичного використання моделей інтелектуального аналізу даних (і чому вони такими є), з огляду на конкретний контекст виявлення сарказму.\n",
    "\n",
    "**Для варіанту 17:**\n",
    "\n",
    "Оцініть масштабованість моделі та обговоріть будь-які необхідні механізми оптимізації для ефективної роботи в реальних умовах.\n",
    "\n",
    "**Для варіанту 18:**\n",
    "\n",
    "Проаналізуйте потенційні проблеми безпеки, що пов’язані з розгортанням моделі, і запропонуйте стратегії для їхнього вирішення.\n",
    "\n",
    "**Для варіанту 19:**\n",
    "\n",
    "Проаналізуйте стратегії роботи з двозначністю та важливість контексту для виявлення сарказму.\n",
    "\n",
    "**Для варіанту 20:**\n",
    "\n",
    "Проаналізуйте можливість розширення моделі для включення інших модальностей (наприклад, зображення, аудіо) для виявлення саркастичних текстів.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
