{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Основні метрики якості класифікації "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матриця невідповідностей\n",
    "\n",
    "Існує багато метрик, що дають змогу обчислити кількісну характеристику бінарного класифікатора. У випадку віднесення одного об'єкта до одного з двох класів можливі 4 результати. Їх зручно відображати за допомогою матриці невідповідностей (з англ. \"[confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\"):\n",
    "\n",
    "- $TP$ = кількість правильно класифікованих цільових об'єктів;\n",
    "- $FP$ = кількість нецільових об'єктів, що класифіковані як цільові (помилки першого роду);\n",
    "- $TN$ = кількість правильно класифікованих нецільових прикладів;\n",
    "- $FN$ = кількість цільових об'єктів, що класифіковані як нецільові (помилки другого роду).\n",
    "\n",
    "<center>\n",
    "<img src=\"../../img/contingency.png\" width = \"500\">\n",
    "</center>\n",
    "\n",
    "Отримати таку таблицю можна за допомогою функції [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html). Необхідно їй на вхід передати дійсні та передбачені класифікатором мітки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "true_labels = np.array([0, 1, 0, 0, 1, 1, 1, 1])\n",
    "predicted_labels = np.array([0, 1, 1, 0, 0, 1, 0, 0])\n",
    "\n",
    "my_metrics = metrics.confusion_matrix(true_labels, predicted_labels)\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Характеристики бінарного класифікатора\n",
    "\n",
    "З огляду на таблицю вище, введемо кілька величин, що кількісно характеризують бінарний класифікатор:\n",
    "\n",
    "$$Recall = TPR = \\frac{TP}{TP + FN},$$\n",
    "\n",
    "\n",
    "$$\\quad SPC = \\frac{TN}{TN + FP},$$\n",
    "\n",
    "\n",
    "$$\\quad Precision = PPV = \\frac{TP}{TP + FP},$$\n",
    "\n",
    "\n",
    "$$\\quad FPR = 1 - SPC,$$\n",
    "\n",
    "\n",
    "$$ACC = \\frac{TP + TN}{TP + TN + FP + FN},$$\n",
    "\n",
    "\n",
    "$$\\quad F1 = 2\\frac{PPV\\cdot TRP}{PPV + TPR}.$$\n",
    "\n",
    "\n",
    "Повнота $TPR$ (True positive rate, recall, sensitivity) - частка правильно класифікованих цільових об'єктів поміж усіх цільових об'єктів.\n",
    "\n",
    "Специфічність $SPC$ (Specificity, true negative rate) - частка правильно класифікованих нецільових об'єктів поміж усіх нецільових об'єктів.\n",
    "\n",
    "Влучність $PPV$ (Positive predictive value, precision) - частка правильно класифікованих цільових об'єктів поміж усіх об'єктів, що класифіковані праильно.\n",
    "\n",
    "$FPR$ (False positive rate) - частка помилково класифікованих нецільових об'єктів поміж усіх нецільових об'єктів.\n",
    "\n",
    "$ACC$ (Accuracy) - частка правильно класифікованих об'єктів поміж усіх об'єктів. $ACC$ є основною характеристикою якості класифікації.\n",
    "\n",
    "$F1$ (F1-measure) - середнє гармонійне влучності та повноти; ця метрика дає змогу врахувати обидві характеристики одночасно.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPV = metrics.precision_score(true_labels, predicted_labels)\n",
    "TPR = metrics.recall_score(true_labels, predicted_labels)\n",
    "F1 = metrics.f1_score(true_labels, predicted_labels)\n",
    "ACC = metrics.accuracy_score(true_labels, predicted_labels)\n",
    "PPV, TPR, F1, ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-крива и AUC\n",
    "\n",
    "Здебільшого бінарні класифікатори мають вигляд $a(x) = \\mbox{sign}(f(x, w) - w_0)$, де $w, w_0$ - параметри алгоритму. Тобто спочатку будується розділяюча поверхня $f(x, w) = w_0 $, після чого об'єкти, що перебувають з однієї сторони від неї класифікуються як цільові, з іншої - як нецільові.\n",
    "\n",
    "ROC-крива (Receiver Operating Characteristic) – це графічна характеристика якості бінарного класифікатора, що виражає залежність TPR від FPR при зміні порога вирішального правила. Ця крива ілюструє, якою буде якість класифікації за різних значень $w_0$ і фіксованому значенні $w$.\n",
    "\n",
    "ROC-крива проходить через точки (0, 0) та (1, 1) і монотонно не зменшується. Чим ближче крива всередині квадрата $[0, 1]\\times[0, 1]$ до лівого верхнього кута, тим краще. Ідеальний варіант - крива, що проходить через три точки: (0, 0), (1, 1) та (0, 1). Діагональ цього квадрата відповідає випадковій класифікації. Типова ROC-крива для класифікатора відповідає кривій на рисунку нижче.\n",
    "\n",
    "<center>\n",
    "<img src=\"../../img/ROC.jpg\" width = \"350\">\n",
    "</center>\n",
    "\n",
    "На практиці ROC-криву завжди оцінюють за незалежною тестовою вибіркою, щоб уникнути перенавчання.\n",
    "\n",
    "Площа під ROC-кривою AUC (Area Under Curve) є кількісною характеристикою якості класифікації, яка не залежить від співвідношення помилок. Чим більше значення AUC, тим \"краще\" є модель класифікації."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дисбаланс класів\n",
    "\n",
    "На практиці у разі дисбалансу класів вдаються до таких [дій](http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/):\n",
    "\n",
    "- зібрати більше даних, особливо об'єктів рідкісного класу (не завжди можливо);\n",
    "- використовувати методи, що ґрунтуються на деревах рішень – [випадковий ліс](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) або [градієнтний бустинг над деревами](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html); дерева не так схильні до проблеми дисбалансу класів;\n",
    "- використовувати метрики типу F1, ROC AUC та [Cohen's kappa](https://en.wikipedia.org/wiki/Cohen%27s_kappa), а не ACC;\n",
    "- використовувати метрику, в якій помилка на об'єкті з рідкісного класу входить із більшою вагою, ніж помилка на об'єкті з типового класу;\n",
    "- застосовувати [oversampling](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis) та [undersampling](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis); у першому випадку до вибірки додаються об'єкти рідкісного класу (семплюються із заміщенням), у другому - об'єкти типового класу випадково видаляються з вибірки;\n",
    "- згенерувати штучні об'єкти рідкісного класу, Synthetic Minority Over-sampling Technique ([SMOTE](https://imbalanced-learn.org/stable/over_sampling.html#smote-adasyn)); додаткова [реалізація](https://github.com/fmfn/UnbalancedDataset) на Python;\n",
    "- розбити один великий клас на кілька менших та застосувати стратегії [One Vs. All](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/) або [One Vs. One](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/);\n",
    "- застосувати алгоритми пошуку викидів або OneClass алгоритми (наприклад, [OneClass SVM](https://machinelearningmastery.com/one-class-classification-algorithms/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Приклади"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "if sys.version_info.major == 2:\n",
    "    from urllib import urlopen\n",
    "elif sys.version_info.major == 3:\n",
    "    from urllib.request import urlopen\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Завантажуємо дані щодо діабету індіанців Піма зі сховища машинного навчання UCI\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "raw_data = urlopen(url)\n",
    "data = np.loadtxt(raw_data, delimiter=\",\")\n",
    "\n",
    "X = data[:, :8]\n",
    "y = data[:, 8]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Задаємо параметр регуляризації терміну помилки\n",
    "C = 10.0\n",
    "\n",
    "# Будуємо класифікатор Suppor Vector Machine\n",
    "lin_svm = LinearSVC(C=C, dual=False).fit(X_train, y_train)\n",
    "y_score = lin_svm.decision_function(X_test)\n",
    "\n",
    "# Обчислюємо ROC-криву та ROC AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Будуємо графік ROC-кривої для певного класу\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вказані вище характеристики можна використовувати для підбору параметрів алгоритмів, наприклад, за допомогою крос-валідації. Знайдемо оптимальну з погляду $F_1$-міри кількість найближчих сусідів алгоритму $kNN$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "k_s = np.arange(1, 50, 2)\n",
    "\n",
    "scores_f1 = list()\n",
    "\n",
    "for k in k_s:\n",
    "    knn.n_neighbors = k\n",
    "    scores_f1.append(np.mean(cross_val_score(knn, X, y, scoring=\"f1\")))\n",
    "\n",
    "plt.figure(1, figsize=(10, 5))\n",
    "plt.clf()\n",
    "plt.plot(k_s, scores_f1, linewidth=2)\n",
    "plt.axvline(k_s[np.argmax(scores_f1)], color=\"r\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.xlabel(\"Parameter k\")\n",
    "plt.xlim(1, 49)\n",
    "plt.title(\"F1-optimal number of neighbors, $k$ = %d\" % k_s[np.argmax(scores_f1)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Багатокласова класифікація\n",
    "\n",
    "У разі, коли кількість класів більше двох, матриця невідповідностей визначається аналогічним чином: на перетині $i$-го рядка і $j$-го стовпця стоїть кількість об'єктів $i$-го класу, що відносяться класифікатором до класу $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.array([0, 1, 2, 0, 1, 2, 0, 1, 2])\n",
    "predicted_labels = np.array([0, 2, 0, 2, 1, 0, 0, 1, 2])\n",
    "\n",
    "my_metrics2 = metrics.confusion_matrix(true_labels, predicted_labels)\n",
    "my_metrics2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. All\n",
    "\n",
    "Багатокласова класифікація може бути зведена до бінарної у різний спосіб. Одним із них є підхід [One vs. All](https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/one-vs-all). Його суть в наступному: для кожного класу $i \\in \\{1, \\dots, k\\}$ навчимо бінарний класифікатор $a_i(x) = \\mbox{sign}f_i(x)$ на початковій вибірці зі зміненими мітками (об'єкти $i$-го класу отримують мітку 1, всі об'єкти, що залишилися - мітку 0). Іншими словами, ми вчимо $a_i$ відрізняти $i$-ий клас від усіх інших. Після цього підсумковий класифікатор будується як $a(x) = \\mbox{argmax}_{i \\in \\{1, \\dots, k\\}} f_i(x)$, тобто він видає клас з найбільшою оцінкою $f_i( x) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Встановлення однієї чи всіх версій лінійної SVM\n",
    "onevsall = OneVsRestClassifier(LinearSVC()).fit(X, y)\n",
    "metrics.accuracy_score(y, onevsall.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корисні посилання:\n",
    "\n",
    "- [Статья](http://habrahabr.ru/post/228963/) \"Как заставить работать бинарный классификатор чуточку лучше\" на Habrahabr\n",
    "- [ROC-кривая](http://www.machinelearning.ru/wiki/index.php?title=ROC-%D0%BA%D1%80%D0%B8%D0%B2%D0%B0%D1%8F)\n",
    "- [Характеристики](https://en.wikipedia.org/wiki/Precision_and_recall) бинарного классификатора\n",
    "- [One vs. All и One vs. One](https://en.wikipedia.org/wiki/Multiclass_classification)\n",
    "- [Quora](https://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set) про несбаланированные выборки\n",
    "- про несбаланированные выборки на [ресурсе](http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/) Machine Learning Mastery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
